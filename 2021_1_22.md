#### 完成bert第二版本迭代

#### 相比第一版解决的问题

1. 在bert模型中将PCA降维处理模块除去，以满足embedding层不能为负值的问题。
2. dropout层中的数字代表灭活率，例如Dropout(0.2)代表灭火20%的神经元。
3. 保留一层transformer。过大的模型结构导致模型难以训练，出现过拟合的问题，且小模型同样可以感受全局视野。



#### 待解决的问题

1. bert训练效率低下，始终维持在0.5左右的准确率
2. 模型如何保存
3. 最后一层如何显示