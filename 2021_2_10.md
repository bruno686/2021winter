看了彭明辉老师的书，愈发觉得自己的研究垃圾

论文的回顾，批判性思考，原创，自己都没做到。

对transformer应用于HSI的一点想法

> attention实质上就是从一个大的区域选取一个小的区域，把这一小部分作为其中一个点的预测变量。
>
> 但是transformer的第一步flat直接铺平显然选定区域太大。全局视野和大区域相同，可以缩小这个区域，即将大的图片切割成若干个集中的块，再进行flat操作。
>
> 预测一个点时用的是全局视野，训练开支大，累赘。
>
> 还有train test split时，直接使用randomstate效果不太好，假设一类数据2000个，另一类数据100个，可能会划分出1800个第一类的train，划分出20个第二类train，这对训练结果影响很大。